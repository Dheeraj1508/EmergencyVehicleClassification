{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emergency_vehicle classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMDSbfO7+iOYvCItdo4L9qT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dheeraj1508/cognitiveAI/blob/main/Emergency_vehicle_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbZdK9gD6_C5"
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjghA6ik727p"
      },
      "source": [
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq9o0xos9E_S"
      },
      "source": [
        "!kaggle datasets download \"abhisheksinghblr/emergency-vehicles-identification\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABRC3bNu9X0Q"
      },
      "source": [
        "!unzip emergency-vehicles-identification.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB7MvrrR9gPN"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlzWkHz_9ns4"
      },
      "source": [
        "train = pd.read_csv('Emergency_Vehicles/train.csv')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK5gyO9Y9xQg"
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.mobilenet_v3 import preprocess_input,MobileNetV3Large\n",
        "# from keras.applications.vgg16 import \n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paqEFScS9-rX"
      },
      "source": [
        "vgg = MobileNetV3Large(input_shape=[224,224] + [3], weights='imagenet', include_top=False)\n",
        "for layer in vgg.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbfS0_8i-N_w"
      },
      "source": [
        "x = Flatten()(vgg.output)\n",
        "x = Dense(128,activation='relu')(x)\n",
        "prediction = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs=vgg.input, outputs=prediction)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3kmll8A-WQz"
      },
      "source": [
        "from keras import optimizers\n",
        "from tensorflow import keras\n",
        "\n",
        "sgd = keras.optimizers.Adam(learning_rate=0.0001,decay=0.000001)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGTldpHo-aU-"
      },
      "source": [
        "# Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4lg5wNM-nzC"
      },
      "source": [
        "train.emergency_or_not=train.emergency_or_not.astype(str)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7VChiNB-e0o",
        "outputId": "3c2dc216-9a04-4761-f335-650b0657224e"
      },
      "source": [
        "train_set = train_datagen.flow_from_dataframe(train,directory='Emergency_Vehicles/train',x_col='image_names',y_col='emergency_or_not',target_size=(224,224),class_mode='binary',batch_size=32)\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1646 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm_COfxw-2sl"
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "my_callbacks = [\n",
        "               ModelCheckpoint('my_model.h5', monitor = 'val_accuracy',verbose = 1,save_weights_only=True, save_best_only = True,mode=\"max\"),\n",
        "               EarlyStopping(monitor='val_loss', patience=8, verbose=0, mode='min'),\n",
        "               ReduceLROnPlateau(monitor='accuracy', factor=0.1, patience=3, verbose=1, mode='min',min_delta=1e-4)\n",
        "]"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJfAH4xp_gj9",
        "outputId": "4b4b7ed3-a016-4ac1-865e-f112e0efbeac"
      },
      "source": [
        "model.fit( train_set,\n",
        "  epochs=15,callbacks=[my_callbacks])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "52/52 [==============================] - 18s 341ms/step - loss: 0.0422 - accuracy: 0.9848\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 2/15\n",
            "52/52 [==============================] - 18s 343ms/step - loss: 0.0477 - accuracy: 0.9848\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 3/15\n",
            "52/52 [==============================] - 18s 341ms/step - loss: 0.0472 - accuracy: 0.9830\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 4/15\n",
            "52/52 [==============================] - 18s 343ms/step - loss: 0.0442 - accuracy: 0.9872\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 5/15\n",
            "52/52 [==============================] - 18s 341ms/step - loss: 0.0481 - accuracy: 0.9854\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 6/15\n",
            "52/52 [==============================] - 18s 342ms/step - loss: 0.0430 - accuracy: 0.9860\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
            "Epoch 7/15\n",
            "52/52 [==============================] - 18s 343ms/step - loss: 0.0401 - accuracy: 0.9885\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 8/15\n",
            "52/52 [==============================] - 18s 341ms/step - loss: 0.0455 - accuracy: 0.9885\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 9/15\n",
            "52/52 [==============================] - 18s 343ms/step - loss: 0.0503 - accuracy: 0.9848\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
            "Epoch 10/15\n",
            "52/52 [==============================] - 18s 341ms/step - loss: 0.0423 - accuracy: 0.9824\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 11/15\n",
            "52/52 [==============================] - 18s 344ms/step - loss: 0.0413 - accuracy: 0.9897\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 12/15\n",
            "52/52 [==============================] - 18s 342ms/step - loss: 0.0415 - accuracy: 0.9872\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 13/15\n",
            "52/52 [==============================] - 18s 342ms/step - loss: 0.0425 - accuracy: 0.9860\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
            "Epoch 14/15\n",
            "52/52 [==============================] - 18s 341ms/step - loss: 0.0407 - accuracy: 0.9885\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 15/15\n",
            "52/52 [==============================] - 18s 343ms/step - loss: 0.0428 - accuracy: 0.9885\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f30a08126d0>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QSJpSsv_mW3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}